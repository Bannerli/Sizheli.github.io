---
title: about
date: 2025-01-12 18:16:32
layout: about
banner_image: /img/motianlun.png
---

### æ­¤é¡µç”¨äºŽè®°å½•å¥½çš„é¡¹ç›®å’Œæ¡ˆä¾‹

**[The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery](https://sakana.ai/ai-scientist/)**
```
The AI scientist, the first comprehensive system for fully automatic scientific discovery, enabling Foundation Models
such as Large Language Models (LLMs) to perform research independently.

We propose and run a fully AI-driven system for automated scientific discovery, applied to machine learning research.
The AI Scientist automates the entire research lifecycle, from generating novel research ideas, writing any necessary code, and executing experiments, to summarizing experimental results, visualizing them, and presenting its findings in a full scientific manuscript.
We also introduce an automated peer review process to evaluate generated papers, write feedback, and further improve results. It is capable of evaluating generated papers with near-human accuracy.
The automated scientific discovery process is repeated to iteratively develop ideas in an open-ended fashion and add them to a growing archive of knowledge, thus imitating the human scientific community.
In this first demonstration, The AI Scientist conducts research in diverse subfields within machine learning research, discovering novel contributions in popular areas, such as diffusion models, transformers, and grokking.
```
## [How to Build an Open-Domain Question Answering System?](https://lilianweng.github.io/posts/2020-10-29-odqa/)
```
A model that can answer any question with regard to factual knowledge can lead to many useful and practical applications, such as working as a chatbot or an AI assistantðŸ¤–. In this post, we will review several common approaches for building such an open-domain question answering system.

Disclaimers given so many papers in the wild:

Assume we have access to a powerful pretrained language model.
We do not cover how to use structured knowledge base (e.g. Freebase, WikiData) here.
We only focus on a single-turn QA instead of a multi-turn conversation style QA.
We mostly focus on QA models that contain neural networks, specially Transformer-based language models.
I admit that I missed a lot of papers with architectures designed specifically for QA tasks between 2017-2019ðŸ˜”
```